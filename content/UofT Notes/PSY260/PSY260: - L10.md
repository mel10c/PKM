#INFO/Secondary/Lecture 

---

# Reading

1. In operant conditioning, () signal whether a particular response will lead to a particular outcome.[^1]
2. () refers to actions or behaviors that benefit another individual at the expense of some cost to the actor. Some such actions may reflect (), or “tit-for-tat” behavior, in which one friend helps another with the expectation that the friend will reciprocate later on.[^2]
3. The () is a part of the brain that helps determine subjective values of punishers, such as whether the intense heat of a chili pepper on the tongue is perceived as pleasurable or painful. The () is a part of the brain that helps determine the motivational value of punishment—that is, what we do about it.[^3]
4. () refers to a strong habit that is maintained despite harmful consequences; if the habit is a behavior, it is called a(n) ().[^4]
5. The part of the brain called the () contains dopamine-producing neurons that project to the () which is important for stimulus–response learning. A different area called the () contains dopamine-producing neurons that project to the frontal cortex and other brain areas.[^5]
6. The () theory states that learning is driven by an organism’s biological need to reduce innate drives to obtain primary reinforcers.[^6]
7. In operant conditioning procedures, () is the process of providing outcomes for a behavior that increase the probability of that behavior occurring again in the future, whereas () is the process of providing outcomes that decrease the probability.[^7]
8. () is the study of how organisms allocate their time and resources among possible options.[^8]
9. In the operant conditioning technique known as (), successive approximations to a desired response are reinforced. In the operant conditioning technique known as (), organisms are gradually trained to execute complicated sequences of discrete responses.[^9]
10. () are stimuli such as food and sleep that can function as reinforcers due to their innate biological value to the organism; if these stimuli are paired with other stimuli that have no biological value, such as money or clicking sounds, those other stimuli can become ()[^10]
11. In a(n) () schedule, every instance of the response is followed by the consequence; in a(n) () schedule, only some responses are reinforced.[^11]
12. An area of the prefrontal cortex called the () is important for learning to predict which outcomes follow particular responses.[^12]
13. If a rat in a Skinner box expects that making a response will result in delivery of sugary water but the rat instead receives only plain water, the phenomenon of () predicts that the rat will respond less than if it had received plain water for its efforts all along.[^13]
14. () are naturally occurring neurotransmitter-like substances that may help signal hedonic value (“liking”) in the brain.[^14]
15. In a(n) () reinforcement schedule, an organism has a choice between multiple possible responses that may each lead to different outcomes. The () predicts that the organism will make each response at a rate proportional to how often that response is reinforced relative to the other choices.[^15]
16. In (), organisms learn to make responses in order to obtain or avoid certain outcomes.[^16]
17. Training paradigms that can cause responses to become less frequent over time include (), in which an undesirable element is delivered after a response, and 9(), in which a desirable element is taken away after the response.[^17]
18. Training paradigms that can cause responses to become more frequent over time include (), in which a desirable element is delivered after a response, and (), in which an undesirable element is taken away after the response.[^18]
19. In a fixed-ratio (FR) schedule of reinforcement, organisms typically give bursts of responding leading up to each reinforcement, followed by a(n) () before the next bout of responding begins.[^19]
20. () refers to the subjective “goodness” of a stimulus. The amount of work an organism will be willing to do to obtain that stimulus depends on the () of that stimulus.[^20]


# Lecture

- What is the difference between [[Classical Conditioning]] and [[Operant Conditioning]]?
    - Focus on the **outcome**.
    - If the outcome occurs **regardless** of responding, the paradigm is classical;
    - If the outcome is **contingent** on a response, the paradigm is operant
    - | Classical Conditioning             | Operant Conditioning                                         |
    |------------------------------------|--------------------------------------------------------------|
    | Environment operates on the animal | Animal operates on the environment                           |
    | Stimulus evokes Response (`S->R`)  | Stimulus evokes a response to produce an outcome (`S->R->O`) |
    | Animal learns CS predicts US       | Animal connects context, behaviour, and outcome              |
    |                                    | Also, operant conditioning is more powerful/flexible         |
- What does `S -> R -> O` each represent in [[Operant Conditioning]]?
- What is Skinner's [[Skinner's Box|method]] of testing his theory?
- What are the 3 major component of [[operant conditioning]]?
- What are the 2 common strategies used in [[Operant Conditioning#Type of Conditioning]]?
- What is a [[Operant Conditioning#Reinforcer|reinforcer]]?
- What is a [[Operant Conditioning#Punishment|punisher]]?
- What are the 4 [[Operant Conditioning#Schedule|schedules]] in OC, real life example of each.
- What are some brain parts involved in operant conditioning?
    - `S -> R` learning: [[Basal Ganglia#Dorsal Stratum]]
    - `R -> O` prediction: [[Prefrontal Cortex#Orbital PFC]]
    - Reinforcement: [[Ventral Tegmental Area]]
        - ==Incentive Salience hypothesis==: dopamine motivates learners to work for reinforcement
        - ==Reward Prediction hypothesis==: dopamine is involved in predicting future reward
          - <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7k4poizx5j312j0u0jua.jpg" width="300">
          - Revisiting [[Drive Reduction Theory]]
              - <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7k4pv7xebj319c0raaeg.jpg" width="300">
  - Punishment: *dorsal anterior cingulate (dACC)* & *Insula*
      - Insula: determine **subjective values** of punishers
      - The **dorsal anterior cingulate (dACC)** might be involved in the **motivational** component of pain/punishment (work harder next time to avoid it)


## Questions




[^1]: discriminative stimuli
[^2]: Premack principle, response deprivation
[^3]: insula; dACC
[^4]: pathological addiction, behavioral addiction
[^5]: SNc (substantia nigra), dorsal striatum, ventrl tegmental area
[^6]: drive reduction theory
[^7]: Reinforcement, punishment
[^8]: behavioural economics
[^9]: shaping, chaining
[^10]: primary reinforcer, secondary reinforcer
[^11]: fixed ratio, variable ratio
[^12]: Orbitofrontal cortex
[^13]: negative contrast
[^14]: dopamine
[^15]: concurrent, matching law
[^16]: operant conditioning
[^17]: positive punishment, negative punishment
[^18]: positive Reinforcement, negative reinforcement
[^19]: postreinforcement pause
[^20]: hedonic value, motivational value
