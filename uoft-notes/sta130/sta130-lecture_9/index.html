<!doctype html><html lang=en><head><meta charset=utf-8><meta name=description content="Classification (Decision) Trees Anatomy of a classification tree  Decision Tree - flowchart-like diagram that shows the various outcomes from a serious of decisions. Advantage is its easy to follow and understand Root node - the starting point of the tree (first parent node), same functionality with terminal (leaf) nodes. Leaf nodes - child nodes, contain a question or criteria to be answered, the answer splits into exactly two child nodes Terminal nodes - the node containing the prediction results of the decision tree."><title>STA130: Lecture_9</title><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" type=image/png href=https://mel10c.github.io/mel.zhu//icon.png><link href=https://mel10c.github.io/mel.zhu/styles.9a8661985b360a1d97e0e538e164abef.min.css rel=stylesheet><link href=https://mel10c.github.io/mel.zhu/styles/_light_syntax.86a48a52faebeaaf42158b72922b1c90.min.css rel=stylesheet id=theme-link><script src=https://mel10c.github.io/mel.zhu/js/darkmode.905e4d2da56a9111aff695a0a4b69900.min.js></script>
<script src=https://mel10c.github.io/mel.zhu/js/util.6f22941e242efae60fd84e7c32e874fa.min.js></script>
<link rel=preload href=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css as=style onload='this.onload=null,this.rel="stylesheet"' integrity=sha384-R4558gYOUz8mP9YWpZJjofhk+zx0AS11p36HnD2ZKj/6JR5z27gSSULCNHIRReVs crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js integrity=sha384-z1fJDqw8ZApjGO3/unPWUPsIymfsJmyrDVWC8Tv/a1HeOtGmkwNd/7xUS0Xcnvsx crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/contrib/auto-render.min.js integrity=sha384-+XBljXPPiv+OzfbB3cVmLHf4hdUFHlWNZN5spNQ7rmHTXpd7WvJum6fIACpNNfIR crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/copy-tex.min.js integrity=sha384-ww/583aHhxWkz5DEVn6OKtNiIaLi2iBRNZXfJRiY1Ai7tnJ9UXpEsyvOITVpTl4A crossorigin=anonymous></script>
<script async src=https://unpkg.com/@floating-ui/core@0.7.3></script>
<script async src=https://unpkg.com/@floating-ui/dom@0.5.4></script>
<script async src=https://mel10c.github.io/mel.zhu/js/popover.f03552ccb84d99ca615d1cfb9abde59e.min.js></script>
<script defer src=https://mel10c.github.io/mel.zhu/js/code-title.ce4a43f09239a9efb48fee342e8ef2df.min.js></script>
<script defer src=https://mel10c.github.io/mel.zhu/js/clipboard.2913da76d3cb21c5deaa4bae7da38c9f.min.js></script>
<script defer src=https://mel10c.github.io/mel.zhu/js/callouts.7723cac461d613d118ee8bb8216b9838.min.js></script>
<script>const SEARCH_ENABLED=!1,LATEX_ENABLED=!0,PRODUCTION=!0,BASE_URL="https://mel10c.github.io/mel.zhu/",fetchData=Promise.all([fetch("https://mel10c.github.io/mel.zhu/indices/linkIndex.5702adc893417d7a266d9ed2e8ebdba1.min.json").then(e=>e.json()).then(e=>({index:e.index,links:e.links})),fetch("https://mel10c.github.io/mel.zhu/indices/contentIndex.29e8901604d17bba5377fc5ce2a7f2c6.min.json").then(e=>e.json())]).then(([{index:e,links:t},n])=>({index:e,links:t,content:n})),render=()=>{const e=new URL(BASE_URL),t=e.pathname,n=window.location.pathname,s=t==n;addCopyButtons(),addTitleToCodeBlocks(),addCollapsibleCallouts(),initPopover("https://mel10c.github.io/mel.zhu",!0);const o=document.getElementById("footer");if(o){const e=document.getElementById("graph-container");if(!e)return requestAnimationFrame(render);e.textContent="";const t=s&&!1;drawGraph("https://mel10c.github.io/mel.zhu",t,[{"/moc":"#4388cc"}],t?{centerForce:1,depth:-1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.5,linkDistance:1,opacityScale:3,repelForce:1,scale:1.4}:{centerForce:1,depth:1,enableDrag:!0,enableLegend:!1,enableZoom:!0,fontSize:.6,linkDistance:1,opacityScale:3,repelForce:2,scale:1.2})}var i=document.getElementsByClassName("mermaid");i.length>0&&import("https://unpkg.com/mermaid@9/dist/mermaid.esm.min.mjs").then(e=>{e.default.init()})},init=(e=document)=>{addCopyButtons(),addTitleToCodeBlocks(),renderMathInElement(e.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}],macros:{'’':"'"},throwOnError:!1})}</script><script type=module>
    import { attachSPARouting } from "https:\/\/mel10c.github.io\/mel.zhu\/js\/router.9d4974281069e9ebb189f642ae1e3ca2.min.js"
    attachSPARouting(init, render)
  </script></head><body><div id=search-container><div id=search-space><input autocomplete=off id=search-bar name=search type=text aria-label=Search placeholder="Search for something..."><div id=results-container></div></div></div><script src=https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js integrity="sha256-i3A0NZGkhsKjVMzFxv3ksk0DZh3aXqu0l49Bbh0MdjE=" crossorigin=anonymous defer></script>
<script defer src=https://mel10c.github.io/mel.zhu/js/full-text-search.e6e2e0c213187ca0c703d6e2c7a77fcd.min.js></script><div class=singlePage><header><h1 id=page-title><a href=https://mel10c.github.io/mel.zhu/>MEL.ZHU</a></h1><div class=spacer></div><div id=search-icon><p>Search</p><svg tabindex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search Icon</title><desc id="desc">Icon to open search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"/><circle cx="8" cy="8" r="7"/></g></svg></div><div class=darkmode><input class=toggle id=darkmode-toggle type=checkbox tabindex=-1>
<label id=toggle-label-light for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="dayIcon" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35"><title>Light Mode</title><path d="M6 17.5C6 16.672 5.328 16 4.5 16h-3C.672 16 0 16.672.0 17.5S.672 19 1.5 19h3C5.328 19 6 18.328 6 17.5zM7.5 26c-.414.0-.789.168-1.061.439l-2 2C4.168 28.711 4 29.086 4 29.5 4 30.328 4.671 31 5.5 31c.414.0.789-.168 1.06-.44l2-2C8.832 28.289 9 27.914 9 27.5 9 26.672 8.329 26 7.5 26zm10-20C18.329 6 19 5.328 19 4.5v-3C19 .672 18.329.0 17.5.0S16 .672 16 1.5v3C16 5.328 16.671 6 17.5 6zm10 3c.414.0.789-.168 1.06-.439l2-2C30.832 6.289 31 5.914 31 5.5 31 4.672 30.329 4 29.5 4c-.414.0-.789.168-1.061.44l-2 2C26.168 6.711 26 7.086 26 7.5 26 8.328 26.671 9 27.5 9zM6.439 8.561C6.711 8.832 7.086 9 7.5 9 8.328 9 9 8.328 9 7.5c0-.414-.168-.789-.439-1.061l-2-2C6.289 4.168 5.914 4 5.5 4 4.672 4 4 4.672 4 5.5c0 .414.168.789.439 1.06l2 2.001zM33.5 16h-3c-.828.0-1.5.672-1.5 1.5s.672 1.5 1.5 1.5h3c.828.0 1.5-.672 1.5-1.5S34.328 16 33.5 16zM28.561 26.439C28.289 26.168 27.914 26 27.5 26c-.828.0-1.5.672-1.5 1.5.0.414.168.789.439 1.06l2 2C28.711 30.832 29.086 31 29.5 31c.828.0 1.5-.672 1.5-1.5.0-.414-.168-.789-.439-1.061l-2-2zM17.5 29c-.829.0-1.5.672-1.5 1.5v3c0 .828.671 1.5 1.5 1.5s1.5-.672 1.5-1.5v-3C19 29.672 18.329 29 17.5 29zm0-22C11.71 7 7 11.71 7 17.5S11.71 28 17.5 28 28 23.29 28 17.5 23.29 7 17.5 7zm0 18c-4.136.0-7.5-3.364-7.5-7.5s3.364-7.5 7.5-7.5 7.5 3.364 7.5 7.5S21.636 25 17.5 25z"/></svg></label><label id=toggle-label-dark for=darkmode-toggle tabindex=-1><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" id="nightIcon" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'"><title>Dark Mode</title><path d="M96.76 66.458c-.853-.852-2.15-1.064-3.23-.534-6.063 2.991-12.858 4.571-19.655 4.571C62.022 70.495 50.88 65.88 42.5 57.5 29.043 44.043 25.658 23.536 34.076 6.47c.532-1.08.318-2.379-.534-3.23-.851-.852-2.15-1.064-3.23-.534-4.918 2.427-9.375 5.619-13.246 9.491-9.447 9.447-14.65 22.008-14.65 35.369.0 13.36 5.203 25.921 14.65 35.368s22.008 14.65 35.368 14.65c13.361.0 25.921-5.203 35.369-14.65 3.872-3.871 7.064-8.328 9.491-13.246C97.826 68.608 97.611 67.309 96.76 66.458z"/></svg></label></div></header><article><h1>STA130: Lecture_9</h1><p class=meta>Last updated
Unknown</p><ul class=tags><li><a href=https://mel10c.github.io/mel.zhu/tags/note/>Note</a></li></ul><aside class=mainTOC><details><summary>Table of Contents</summary><nav id=TableOfContents><ol><li><a href=#anatomy-of-a-classification-tree>Anatomy of a classification tree</a></li><li><a href=#build-a-simple-tree>Build a Simple Tree</a><ol><li><a href=#code-to-build-the-tree-using-r>Code to build the tree using <code>R</code></a></li><li><a href=#geometric-interpretation>Geometric interpretation</a></li></ol></li><li><a href=#how-to-fit-a-tree-mostly-done-by-r>How to fit a Tree (mostly done by <code>R</code>)</a></li><li><a href=#evaluating-the-prediction-accuracy-of-a-tree-categorical-predictor>Evaluating the prediction accuracy of a tree (categorical predictor)</a><ol><li><a href=#strategies-for-assessing-the-prediction-accuracy-of-a-tree>Strategies for assessing the prediction accuracy of a tree</a></li></ol></li><li><a href=#comparing-different-trees>Comparing different trees</a></li><li><a href=#response-variable-has-more-than-2-levels>Response variable has more than 2 levels</a></li><li><a href=#limitations-for-training-and-testing-approach>Limitations for training and testing approach</a></li></ol></nav></details></aside><a href=#classification-decision-trees><h1 id=classification-decision-trees><span class=hanchor arialabel=Anchor># </span>Classification (Decision) Trees</h1></a><a href=#anatomy-of-a-classification-tree><h2 id=anatomy-of-a-classification-tree><span class=hanchor arialabel=Anchor># </span>Anatomy of a classification tree</h2></a><img src=https://techvidvan.com/tutorials/wp-content/uploads/sites/2/2020/05/Parts-of-a-Decision-Tree.jpg alt=tree style=zoom:50%><ul><li><u>Decision Tree</u> - flowchart-like diagram that shows the various outcomes from a serious of decisions. Advantage is its easy to follow and understand</li><li><u>Root node</u> - the starting point of the tree (first parent node), same functionality with terminal (leaf) nodes.</li><li><u>Leaf nodes</u> - child nodes, contain a question or criteria to be answered, the answer splits into exactly <strong>two child</strong> nodes</li><li><u>Terminal nodes</u> - the node containing the prediction results of the decision tree.</li></ul><a href=#build-a-simple-tree><h2 id=build-a-simple-tree><span class=hanchor arialabel=Anchor># </span>Build a Simple Tree</h2></a><a href=#code-to-build-the-tree-using-r><h3 id=code-to-build-the-tree-using-r><span class=hanchor arialabel=Anchor># </span>Code to build the tree using <code>R</code></h3></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=line><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>rpart</span><span class=p>)</span>  <span class=c1># Package which includes the rpart() function, used to build trees</span>
</span></span><span class=line><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>partykit</span><span class=p>)</span>  <span class=c1># Package which includes as.party(), used to visualize trees</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tree</span> <span class=o>&lt;-</span> <span class=nf>rpart</span><span class=p>(</span><span class=o>&lt;</span><span class=n>y</span><span class=o>&gt;</span> <span class=o>~</span> <span class=o>&lt;</span><span class=n>x_1</span><span class=o>&gt;</span> <span class=o>+</span> <span class=o>&lt;</span><span class=n>x_2</span><span class=o>&gt;</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=o>&lt;</span><span class=n>dataset</span><span class=o>&gt;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>plot</span><span class=p>(</span><span class=nf>as.party</span><span class=p>(</span><span class=n>tree</span><span class=p>),</span> <span class=n>gp</span><span class=o>=</span><span class=nf>gpar</span><span class=p>(</span><span class=n>cex</span><span class=o>=</span><span class=m>1</span><span class=p>),</span> <span class=n>type</span><span class=o>=</span><span class=s>&#34;simple&#34;</span><span class=p>)</span>  <span class=c1># gp is for visual adjusting</span>
</span></span></code></pre></td></tr></table></div></div><blockquote><a href=#predicting-which-people-have-trouble-sleeping-using-decision-tree-in-r><h5 id=predicting-which-people-have-trouble-sleeping-using-decision-tree-in-r><span class=hanchor arialabel=Anchor># </span>Predicting which people have trouble sleeping using Decision Tree in <code>R</code></h5></a><ul><li>Using the sample of 2,500 individual&rsquo;s survey in the US between 2009 and 2012 (<code>NHANES</code>)</li><li><code>SleepTrouble</code> as response variable; <code>SleepHrsNight</code> and <code>DaysPhysHlthBad</code> as predictors</li></ul><p><img src=https://tva1.sinaimg.cn/large/008eGmZEly1gotbxdd0qfj30fv06rab5.jpg width=auto alt="Screen Shot 2021-03-22 at 16.13.57"></p></blockquote><a href=#geometric-interpretation><h3 id=geometric-interpretation><span class=hanchor arialabel=Anchor># </span>Geometric interpretation</h3></a><ul><li>Extended decision tree visual<div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=line><span class=cl><span class=nf>plot</span><span class=p>(</span><span class=nf>as.party</span><span class=p>(</span><span class=n>tree</span><span class=p>),</span> <span class=n>type</span><span class=o>=</span><span class=s>&#34;extended&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><ul><li><img src=https://tva1.sinaimg.cn/large/008eGmZEly1gotc7gwhrlj31520ty1af.jpg alt="Screen Shot 2021-03-22 at 16.22.50" style=zoom:25%> (produced by the code above)</li></ul></li><li>This is a &ldquo;scattered plot&rdquo;<ul><li>The vertical line shows the split of the first predictor, while the horizontal lines shows the split of the second predictor</li><li><img src="/Users/melaneyzhu/Desktop/Screen Shot 2021-03-22 at 16.22.55.png" alt="Screen Shot 2021-03-22 at 16.22.55" style=zoom:25%> (Code is not shown [not important here])</li></ul></li></ul><a href=#how-to-fit-a-tree-mostly-done-by-r><h2 id=how-to-fit-a-tree-mostly-done-by-r><span class=hanchor arialabel=Anchor># </span>How to fit a Tree (mostly done by <code>R</code>)</h2></a><blockquote><p>Goal: each terminal (leaf) node to be as pure as possible; and the tree as simple as possible</p></blockquote><ol><li>A <strong>response variable</strong> ($y$ what the tree want to predict)</li><li>A set of candidate <strong>predictors</strong> ($x_i, i=1, \dots, M$)</li><li>A set of binary <strong>questions</strong> (ex. $x_i \ge 25$)
[Need <em>categorical response</em> and <em>binary splits</em>, binary splits are based on predictors:]<ul><li><em>Numerical predictors</em> can be split based on the range (ex. $x_i \ge 25$)</li><li><em>Categorical predictors</em> can be split based on the categories (choose 2 if there is more)</li></ul></li><li>A <strong>method to evaluate if a spits</strong><ul><li>[A &ldquo;good&rdquo; split is one that makes its <em>child</em> node as <u>pure</u> as possible]<ul><li><u>Pure node</u> - if the node only contains observations from one class</li><li><u>Impure node</u> - if the node contains an equal mix of all the classes (50% each category)</li><li>Measures of impurity<ul><li>$$ Gini(t) = 1 - (w_i (t))^2 + (w_2 (t))^2 $$</li><li>$$ Entropgy(t) = -w_1 (t) \log_2 (w_1(t)) + w_2(t) \log_2 (w_2(t)) $$</li></ul></li></ul></li><li>[The &ldquo;best&rdquo; split is the one with the biggest decrease in impurity $\Delta I$]<ul><li>For each candidate split, calculate the decrease in impurity as $\Delta I$ (measures the pure of the two child, compared tot he parent&rsquo;s pure)</li><li>After looking at each of the potential predictor and each possible splits, choose the best</li></ul></li></ul></li><li>A rule to decide <strong>when to stop splitting</strong><ul><li>Simple rule: set a threshold $\beta > 0$</li><li>If none of the splits of a node makes the tree at least $\beta$-units pure, then don&rsquo;t split further</li></ul></li><li>A way to <strong>make a prediction</strong> for each terminal node</li></ol><a href=#evaluating-the-prediction-accuracy-of-a-tree-categorical-predictor><h2 id=evaluating-the-prediction-accuracy-of-a-tree-categorical-predictor><span class=hanchor arialabel=Anchor># </span>Evaluating the prediction accuracy of a tree (categorical predictor)</h2></a><ul><li><p><u>Accuracy rate</u> - how close the predictions are to the true values, on average
$$
Accuracy = \frac{\text{# of correct predictors}}{\text{total # of predictions}}
$$</p></li><li><p><u>Confusion matrix</u> - a table with one row for each predicted class and one column for each tree class</p><table><thead><tr><th></th><th>Actually positive</th><th>Actually negative</th></tr></thead><tbody><tr><td>Predict positive</td><td><strong>True positives (TP)</strong></td><td><em>False positives (FP)</em></td></tr><tr><td>Predict negative</td><td><em>False negative (FN)</em></td><td><strong>True negatives (TN)</strong></td></tr></tbody></table></li><li><p>For a binary response, there are 2 types of errors [incorrect, want rate to <strong>close to 0</strong>]</p><ul><li><u>False positive error</u> - predict (+) by D.T. but actually is (-) [inconvenience]</li><li><u>False negative error</u> - predict (-) by D.T. but actually is (+) [might cause negative impact]</li></ul></li><li><p>2 important properties of the prediction model [correct, want <strong>close to 1</strong>]</p><ul><li><strong><u>Sensitivity</u></strong> - <em>proportion</em> of actual (+) correctly predicted as (+)</li><li><strong><u>Specificity</u></strong> - <em>proportion</em> of actual (-) correctly predicted as (-)</li></ul></li><li><p>Another way to define the accuracy rate:
$$
Accuracy = \frac{\text{# True positives}~ + ~\text{# True negatives}}{\text{Total # of predictions}}
$$</p></li></ul><a href=#strategies-for-assessing-the-prediction-accuracy-of-a-tree><h3 id=strategies-for-assessing-the-prediction-accuracy-of-a-tree><span class=hanchor arialabel=Anchor># </span>Strategies for assessing the prediction accuracy of a tree</h3></a><ol><li>Randomly divide data into &ldquo;training&rdquo; and &ldquo;testing&rdquo; datasets (80% for training, and 20% for testing)</li><li>Fit the tree based on the training data only</li><li>Run the test through the fitted tree to make predictions, and construct a confusion matrix to see how many are correctly/incorrectly classified</li></ol><blockquote><a href=#example-with-the-nhanes-dataset><h5 id=example-with-the-nhanes-dataset><span class=hanchor arialabel=Anchor># </span>Example with the <code>NHANES</code> dataset</h5></a><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-R data-lang=R><span class=line><span class=cl><span class=n>NHANES</span> <span class=o>&lt;-</span> <span class=n>NHANES</span> <span class=o>%&gt;%</span> <span class=nf>rowid_to_column</span><span class=p>()</span>  <span class=c1># add a new ID to columm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Find n, the total number of observations</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>&lt;-</span> <span class=nf>nrow</span><span class=p>(</span><span class=n>NHANES</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Set training and testing data</span>
</span></span><span class=line><span class=cl><span class=nf>set.seed</span><span class=p>(</span><span class=m>1002</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>train_ids</span> <span class=o>&lt;-</span> <span class=nf>sample</span><span class=p>(</span><span class=m>1</span><span class=o>:</span><span class=n>n</span><span class=p>,</span> <span class=n>size</span><span class=o>=</span> <span class=nf>round</span><span class=p>(</span><span class=m>0.8</span><span class=o>*</span><span class=n>n</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>train</span> <span class=o>&lt;-</span> <span class=n>NHANES</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=n>rowid</span> <span class=o>%in%</span> <span class=n>train_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>test</span> <span class=o>&lt;-</span> <span class=n>NHANES</span> <span class=o>%&gt;%</span> <span class=nf>filter</span><span class=p>(</span><span class=o>!</span><span class=p>(</span><span class=n>rowid</span> <span class=o>%in%</span> <span class=n>train_ids</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Fitting the data</span>
</span></span><span class=line><span class=cl><span class=n>tree</span> <span class=o>&lt;-</span> <span class=nf>rpart</span><span class=p>(</span><span class=n>SleepTrouble</span> <span class=o>~</span> <span class=n>SleepHrsNight</span> <span class=o>+</span> <span class=n>DayPhysHlthBad</span><span class=p>,</span> <span class=n>data</span><span class=o>=</span><span class=n>train</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>plot</span><span class=p>(</span><span class=nf>as.party</span><span class=p>(</span><span class=n>tree</span><span class=p>),</span> <span class=n>type</span><span class=o>=</span><span class=s>&#34;simple&#34;</span><span class=p>,</span> <span class=n>gp</span><span class=o>=</span><span class=nf>gpar</span><span class=p>(</span><span class=n>cex</span><span class=o>=</span><span class=m>0.8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Constructing confusion matrix</span>
</span></span><span class=line><span class=cl><span class=n>tree_pred</span> <span class=o>&lt;-</span> <span class=nf>predict</span><span class=p>(</span><span class=n>tree</span><span class=p>,</span> <span class=n>newdata</span><span class=o>=</span><span class=n>test</span><span class=p>,</span> <span class=n>type</span><span class=o>=</span><span class=s>&#34;class&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nf>table</span><span class=p>(</span><span class=n>tree_pred</span><span class=p>,</span> <span class=n>test</span><span class=o>$</span><span class=n>SleepTrouble</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>##
</span></span><span class=line><span class=cl>##	tree_pred	No		Yes
</span></span><span class=line><span class=cl>##		   No	339		133
</span></span><span class=line><span class=cl>##		  Yes	9		19
</span></span></code></pre></td></tr></table></div></div><ul><li>Accuracy = $(339 + 19)/(339 + 133 + 9 + 19) = 358/500 = 0.716$</li><li>False positive rate = $9 / (339 + 9) = 9/348 = 0.026$</li><li>False negative rate = $133 / (133 + 19) = 133/152 = 0.875$ (not so good)</li></ul></blockquote><a href=#comparing-different-trees><h2 id=comparing-different-trees><span class=hanchor arialabel=Anchor># </span>Comparing different trees</h2></a><ol><li>Use <code>rpart()</code> to specify different sets of candidate predictors to predict the same response</li><li>(optional) Plot all trees&rsquo; visual out with <code>as.party()</code></li><li>Constructing confusion matrices for all trees (based on the <strong>testing</strong> data)</li><li>Constructing confusion matrices for all trees (based on the <strong>training</strong> data)</li><li>Combine the 2 tables above, use it to compare the trees<ul><li>Understand the priority between accuracy/sensitivity/specificity for the given problem<ul><li>Ideally all of these should be high, but may have to prioritize one over another</li></ul></li><li>Ideally, prefer the tree to be less complex (less risk of overhitting, more interpretable)</li></ul></li></ol><a href=#response-variable-has-more-than-2-levels><h2 id=response-variable-has-more-than-2-levels><span class=hanchor arialabel=Anchor># </span>Response variable has more than 2 levels</h2></a><ul><li>The classification tree method still works</li><li>The confusion matrix is a $m \times m$ matrix, where $m$ is the number of levels of the response</li><li>Sensitivity and specificity does not apply anymore</li><li>Careful for the different types of possible errors</li></ul><a href=#limitations-for-training-and-testing-approach><h2 id=limitations-for-training-and-testing-approach><span class=hanchor arialabel=Anchor># </span>Limitations for training and testing approach</h2></a><ul><li>The accuracy of trees (or RMSE for linear regression models) depends on which observations are in the training/testing sets, which are determined at random</li><li>Only a single subset of the observations are used to build(or fit) the prediction model<ul><li>Statistical methods perform better when more data is used to fit them</li><li>This approach may make the error rate look a bit worse than it would be if all of the data were used to fit the model (without splitting the training and testing set)</li></ul></li></ul></article><hr><div class=page-end id=footer><div class=backlinks-container><h3>Backlinks</h3><ul class=backlinks><li>No backlinks found</li></ul></div><div><script async src=https://cdn.jsdelivr.net/npm/d3@6.7.0/dist/d3.min.js integrity="sha256-+7jaYCp29O1JusNWHaYtgUn6EhuP0VaFuswhNV06MyI=" crossorigin=anonymous></script><h3>Interactive Graph</h3><div id=graph-container></div><style>:root{--g-node:var(--secondary);--g-node-active:var(--primary);--g-node-inactive:var(--visited);--g-link:var(--outlinegray);--g-link-active:#5a7282}</style><script src=https://mel10c.github.io/mel.zhu/js/graph.2d9e48dbe7ea47c0ef1c58296ce14448.js></script></div></div><div id=contact_buttons><footer><p>Made by Melaney Zhu using <a href=https://github.com/jackyzha0/quartz>Quartz</a>, © 2023</p><ul><li><a href=https://mel10c.github.io/mel.zhu/>Home</a></li><li><a href=https://www.instagram.com/melaney_dxl/>Instagram</a></li><li><a href=https://github.com/mel10c>GitHub</a></li><li><a href=https://linkedin.com/in/melzyy>LinkedIn</a></li><li><a href=https://github.com/mel10c/mel.zhu/blob/hugo/content/documents/Resume.pdf>Resume</a></li></ul></footer></div></div></body></html>